{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f23616",
   "metadata": {},
   "source": [
    "# <font>Big Data Real-Time Analytics com Python e Spark</font>\n",
    "\n",
    "\n",
    "### <font>Data Science Aplicada em Logística com Spark SQL</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf12917",
   "metadata": {},
   "source": [
    "![title](imagens/sparksql.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e1c6b3",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244ed81",
   "metadata": {},
   "source": [
    "O objetivo deste projeto é analisar um conjunto de dados de uma transportadora responsável por entrega de produtos. Diversos veículos realizam diversas entregas em diferentes horários do dia. Usando Spark SQL vamos extrair insights e compreender como está a performance da logística de entrega da empresa.\n",
    "\n",
    "As soluções para cada pergunta de negócio são apresentadas em Linguagem SQL e com o uso de funções do Spark SQL. Temas como agregação, funções Window e parse de data também são abordados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca5c5f6",
   "metadata": {},
   "source": [
    "## Definição do problema e fonte de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c142f8",
   "metadata": {},
   "source": [
    "Uma transportadora possui diversos veículos que são usados para entregas. Cada veículo realiza diversas entregas por dia e o horário exato de cada entrega é registrado. A empresa tenta otimizar o percurso de cada veículo fazendo com que um mesmo veículo faça todas as entregas em cada região, reduzindo assim o tempo entre uma entrega e outra. \n",
    "\n",
    "Os dados usados neste trabalho são fictícios e o dataset tem 3 colunas: id do veículo, a entrega que foi realiza e o horário. Usando Spark SQL faremos uma série de análises nos dados a fim de verificar como está a performance da logística de entrega da empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16babd0c",
   "metadata": {},
   "source": [
    "## Preparando o Ambiente Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf75c895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494b1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652aefb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import lead  \n",
    "from pyspark.sql.functions import min, max\n",
    "from pyspark.sql.functions import unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a12b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o Spark Context\n",
    "sc = SparkContext(appName = \"Mini-Projeto4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8822e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a sessão\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7cb1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://JOAOMARCELO.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Mini-Projeto4</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x21282d21070>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d3612",
   "metadata": {},
   "source": [
    "## Carregando os Dados Como Dataframe do Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aee0316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome do arquivo\n",
    "arquivo = 'dados/dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81977370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega como dataframe do Spark\n",
    "# Não usaremos Pandas pois não vamos fazer análise exploratória de dados\n",
    "df = spark.read.csv(arquivo, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae1e1c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975b2a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "+----------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91b5982",
   "metadata": {},
   "source": [
    "## Criando Tabela Temporária\n",
    "\n",
    "Criamos uma tabela temporária para executar consultas SQL nos dados. A tabela temporária existe somente nesta sessão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "412b9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma tabela temporária\n",
    "df.createOrReplaceTempView(\"tb_logistica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8690490",
   "metadata": {},
   "source": [
    "## Executando Queries SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "296f9d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  col_name|\n",
      "+----------+\n",
      "|id_veiculo|\n",
      "|   entrega|\n",
      "|   horario|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando as colunas da tabela\n",
    "spark.sql(\"SHOW COLUMNS FROM tb_logistica\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66abee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizando os 5 primeiros registros\n",
    "spark.sql(\"SELECT * FROM tb_logistica LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0b4df75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|  col_name|data_type|comment|\n",
      "+----------+---------+-------+\n",
      "|id_veiculo|   string|   NULL|\n",
      "|   entrega|   string|   NULL|\n",
      "|   horario|   string|   NULL|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe da tabela\n",
    "spark.sql(\"DESCRIBE tb_logistica\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19493900",
   "metadata": {},
   "source": [
    "## Queries SQL x Dot Notation no Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e15fa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|veiculo|  entrega|\n",
      "+-------+---------+\n",
      "|    298|Entrega 1|\n",
      "|    298|Entrega 2|\n",
      "|    298|Entrega 3|\n",
      "|    298|Entrega 4|\n",
      "|    298|Entrega 5|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query SQL\n",
    "spark.sql('SELECT id_veiculo AS veiculo, entrega FROM tb_logistica LIMIT 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fa2479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|veiculo|  entrega|\n",
      "+-------+---------+\n",
      "|    298|Entrega 1|\n",
      "|    298|Entrega 2|\n",
      "|    298|Entrega 3|\n",
      "|    298|Entrega 4|\n",
      "|    298|Entrega 5|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dot Notation\n",
    "df.select(col('id_veiculo').alias('veiculo'), 'entrega').limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950e0f2",
   "metadata": {},
   "source": [
    "## Usando Funções SQL do Spark SQL\n",
    "\n",
    "Embora seja mais fácil usar direto Linguagem SQL, as funções do Spark SQL são otimizadas para o trabalho em ambiente distribuído. Se estiver com problemas de performance ao processar grandes conjuntos de dados, faça o teste com SQL e com o uso de funções e compare os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d298506d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id_veiculo: string, entrega: string, horario: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Após o nome do dataframe, digite . (ponto) e pressione a tecla tab para visualizar as funções (métodos) disponíveis\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c4b3a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_veiculo', 'entrega', 'horario']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colunas do dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "472dd155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos converter um Spark DataFrame para um Pandas DataFrame (e assim utilizar métodos do Pandas)\n",
    "pandasDF = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20925954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pandasDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a81da09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_veiculo    entrega horario\n",
      "0         298  Entrega 1   7:58a\n",
      "1         298  Entrega 2   8:04a\n",
      "2         298  Entrega 3   8:17a\n",
      "3         298  Entrega 4   8:28a\n",
      "4         298  Entrega 5   8:33a\n",
      "5         298  Entrega 6   8:39a\n",
      "6         298  Entrega 7   9:07a\n",
      "7         315  Entrega 1   6:05a\n",
      "8         315  Entrega 2   6:14a\n",
      "9         315  Entrega 3   6:24a\n",
      "10        315  Entrega 4   6:38a\n",
      "11        315  Entrega 5   6:45a\n",
      "12        315  Entrega 6   6:56a\n",
      "13        315  Entrega 7   7:32a\n",
      "14        457  Entrega 1   5:04a\n",
      "15        457  Entrega 2   5:13a\n",
      "16        457  Entrega 3   5:27a\n",
      "17        457  Entrega 4   5:39a\n",
      "18        457  Entrega 5   5:47a\n",
      "19        457  Entrega 6   6:21a\n",
      "20        457  Entrega 7   6:38a\n"
     ]
    }
   ],
   "source": [
    "print(pandasDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ac7f3",
   "metadata": {},
   "source": [
    "### Métodos Select e Collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deddc946",
   "metadata": {},
   "source": [
    "> Função select()\n",
    "\n",
    "PySpark select() é uma função (método) de transformação, portanto, retorna um novo \n",
    "DataFrame com as colunas selecionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "032f8df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|id_veiculo|  entrega|\n",
      "+----------+---------+\n",
      "|       298|Entrega 1|\n",
      "|       298|Entrega 2|\n",
      "|       298|Entrega 3|\n",
      "|       298|Entrega 4|\n",
      "|       298|Entrega 5|\n",
      "|       298|Entrega 6|\n",
      "|       298|Entrega 7|\n",
      "|       315|Entrega 1|\n",
      "|       315|Entrega 2|\n",
      "|       315|Entrega 3|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecionando dados de duas colunas\n",
    "df.select('id_veiculo', 'entrega').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e155ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|id_veiculo|  entrega|\n",
      "+----------+---------+\n",
      "|       298|Entrega 1|\n",
      "|       298|Entrega 2|\n",
      "|       298|Entrega 3|\n",
      "|       298|Entrega 4|\n",
      "|       298|Entrega 5|\n",
      "|       298|Entrega 6|\n",
      "|       298|Entrega 7|\n",
      "|       315|Entrega 1|\n",
      "|       315|Entrega 2|\n",
      "|       315|Entrega 3|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Também podemos utilizar esta notação\n",
    "df.select(df.id_veiculo, df.entrega).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13f8c048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|id_veiculo|  entrega|\n",
      "+----------+---------+\n",
      "|       298|Entrega 1|\n",
      "|       298|Entrega 2|\n",
      "|       298|Entrega 3|\n",
      "|       298|Entrega 4|\n",
      "|       298|Entrega 5|\n",
      "|       298|Entrega 6|\n",
      "|       298|Entrega 7|\n",
      "|       315|Entrega 1|\n",
      "|       315|Entrega 2|\n",
      "|       315|Entrega 3|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A função col é outra alternativa\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col('id_veiculo'), col('entrega')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3892bba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|id_veiculo|  entrega|\n",
      "+----------+---------+\n",
      "|       298|Entrega 1|\n",
      "|       298|Entrega 2|\n",
      "|       298|Entrega 3|\n",
      "|       298|Entrega 4|\n",
      "|       298|Entrega 5|\n",
      "|       298|Entrega 6|\n",
      "|       298|Entrega 7|\n",
      "|       315|Entrega 1|\n",
      "|       315|Entrega 2|\n",
      "|       315|Entrega 3|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos selecionar todas as colunas de um dataframe cujos nomes estejam em uma lista\n",
    "nomes_colunas = ['id_veiculo', 'entrega']\n",
    "df.select(*nomes_colunas).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf51c3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|id_veiculo|  entrega|\n",
      "+----------+---------+\n",
      "|       298|Entrega 1|\n",
      "|       298|Entrega 2|\n",
      "|       298|Entrega 3|\n",
      "|       298|Entrega 4|\n",
      "|       298|Entrega 5|\n",
      "|       298|Entrega 6|\n",
      "|       298|Entrega 7|\n",
      "|       315|Entrega 1|\n",
      "|       315|Entrega 2|\n",
      "|       315|Entrega 3|\n",
      "|       315|Entrega 4|\n",
      "|       315|Entrega 5|\n",
      "|       315|Entrega 6|\n",
      "|       315|Entrega 7|\n",
      "|       457|Entrega 1|\n",
      "|       457|Entrega 2|\n",
      "|       457|Entrega 3|\n",
      "|       457|Entrega 4|\n",
      "|       457|Entrega 5|\n",
      "|       457|Entrega 6|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mesmo exemplo anterior mas agora com list comprehension\n",
    "df.select([coluna for coluna in nomes_colunas]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85829f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|veiculo|  entrega|\n",
      "+-------+---------+\n",
      "|    298|Entrega 1|\n",
      "|    298|Entrega 2|\n",
      "|    298|Entrega 3|\n",
      "|    298|Entrega 4|\n",
      "|    298|Entrega 5|\n",
      "|    298|Entrega 6|\n",
      "|    298|Entrega 7|\n",
      "|    315|Entrega 1|\n",
      "|    315|Entrega 2|\n",
      "|    315|Entrega 3|\n",
      "+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos renomear colunas para facilitar a consulta aos dados\n",
    "df.select('id_veiculo', 'entrega').withColumnRenamed('id_veiculo', 'veiculo').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef2de641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|veiculo|  entrega|\n",
      "+-------+---------+\n",
      "|    298|Entrega 1|\n",
      "|    298|Entrega 2|\n",
      "|    298|Entrega 3|\n",
      "|    298|Entrega 4|\n",
      "|    298|Entrega 5|\n",
      "|    298|Entrega 6|\n",
      "|    298|Entrega 7|\n",
      "|    315|Entrega 1|\n",
      "|    315|Entrega 2|\n",
      "|    315|Entrega 3|\n",
      "+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Também podemos usar um alias para renomear coluna\n",
    "df.select(col('id_veiculo').alias('veiculo'), 'entrega').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "383eb5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "+----------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45404d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|horario|\n",
      "+-------+\n",
      "|  7:58a|\n",
      "|  8:04a|\n",
      "|  8:17a|\n",
      "+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecionando colunas pelo índice\n",
    "# A partir da coluna de índice 2 retorne as 3 primeiras linhas\n",
    "df.select(df.columns[2:]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "482e6253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|  entrega|\n",
      "+---------+\n",
      "|Entrega 1|\n",
      "|Entrega 2|\n",
      "|Entrega 3|\n",
      "|Entrega 4|\n",
      "|Entrega 5|\n",
      "|Entrega 6|\n",
      "|Entrega 7|\n",
      "|Entrega 1|\n",
      "|Entrega 2|\n",
      "|Entrega 3|\n",
      "|Entrega 4|\n",
      "|Entrega 5|\n",
      "|Entrega 6|\n",
      "|Entrega 7|\n",
      "|Entrega 1|\n",
      "|Entrega 2|\n",
      "|Entrega 3|\n",
      "|Entrega 4|\n",
      "|Entrega 5|\n",
      "|Entrega 6|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecionando colunas através de expressões regulares\n",
    "# https://docs.python.org/3.9/library/re.html\n",
    "df.select(df.colRegex(\"`^.*Entrega*`\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca4606b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# O dataframe original segue intacto\n",
    "df.show(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc789294",
   "metadata": {},
   "source": [
    "> Vejamos agora a função collect()\n",
    "\n",
    "PySpark collect() é uma função (método) de ação que é usada para recuperar todos os \n",
    "elementos do conjunto de dados (de todos os nós) para o nó do driver (master) do cluster Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddc09d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id_veiculo='298', entrega='Entrega 1', horario='7:58a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 2', horario='8:04a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 3', horario='8:17a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 4', horario='8:28a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 5', horario='8:33a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 6', horario='8:39a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 7', horario='9:07a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 1', horario='6:05a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 2', horario='6:14a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 3', horario='6:24a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 4', horario='6:38a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 5', horario='6:45a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 6', horario='6:56a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 7', horario='7:32a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 1', horario='5:04a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 2', horario='5:13a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 3', horario='5:27a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 4', horario='5:39a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 5', horario='5:47a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 6', horario='6:21a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 7', horario='6:38a')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retornando cada linha do dataframe como um objeto do tipo Row\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6e37e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O método collect() retorna uma lista de linhas\n",
    "new_df = df.collect()\n",
    "type(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d034257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7:58a'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos \"fatiar\" as estruturas retornadas por collect()\n",
    "# Neste caso retornamos o elemento da primeira linha e terceira coluna\n",
    "df.collect()[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dd5ba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298,Entrega 1\n",
      "298,Entrega 2\n",
      "298,Entrega 3\n",
      "298,Entrega 4\n",
      "298,Entrega 5\n",
      "298,Entrega 6\n",
      "298,Entrega 7\n",
      "315,Entrega 1\n",
      "315,Entrega 2\n",
      "315,Entrega 3\n",
      "315,Entrega 4\n",
      "315,Entrega 5\n",
      "315,Entrega 6\n",
      "315,Entrega 7\n",
      "457,Entrega 1\n",
      "457,Entrega 2\n",
      "457,Entrega 3\n",
      "457,Entrega 4\n",
      "457,Entrega 5\n",
      "457,Entrega 6\n",
      "457,Entrega 7\n"
     ]
    }
   ],
   "source": [
    "# Como collect() retorna uma lista, podemos percorrer a lista com um loop e concatenar as colunas, por exemplo\n",
    "for row in df.collect():\n",
    "    print(row['id_veiculo'] + \",\" + str(row['entrega']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28ef4729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id_veiculo='298'),\n",
       " Row(id_veiculo='298'),\n",
       " Row(id_veiculo='298'),\n",
       " Row(id_veiculo='298')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos ainda combinar select e collect\n",
    "# Filtramos colunas com select e filtramos linhas com collect\n",
    "dataCollect = df.select(\"id_veiculo\").collect()[0:4][:]\n",
    "dataCollect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe94a0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id_veiculo='298', entrega='Entrega 3', horario='8:17a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 4', horario='8:28a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 2', horario='6:14a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 3', horario='6:24a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 4', horario='6:38a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 6', horario='6:56a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 2', horario='5:13a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 4', horario='5:39a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 7', horario='6:38a')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos extrair primeiro uma amostra do dataframe e então coletar o resultado\n",
    "df.sample(0.6).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f631cd",
   "metadata": {},
   "source": [
    "### Métodos Filter e Where"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69feaddd",
   "metadata": {},
   "source": [
    "A função filter() do Spark é usada para filtrar as linhas do RDD/DataFrame com base na \n",
    "condição ou expressão SQL fornecida.\n",
    "\n",
    "Também podemos utilizar a função where() em vez do filter() se estiver mais confortável \n",
    "com a Linguagem SQL, pois ambas as funções operam de forma exatamente igual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cbebfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos filtrar os dados retornados com a função filter()\n",
    "df.filter(\"entrega == 'Entrega 2'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45059b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos filtrar os dados retornados com a função filter() usando a negação\n",
    "df.filter(\"entrega != 'Entrega 2'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c64f46e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 2|  8:04a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos filtrar usando múltiplas condições\n",
    "df.filter((df.entrega == \"Entrega 2\") & (df.id_veiculo == 298)).show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3c2a3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtro baseado em lista\n",
    "lista_id_veiculos = [298, 300, 400]\n",
    "df.filter(df.id_veiculo.isin(lista_id_veiculos)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05397735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alguma entrega ocorreu no minuto 38 de qualquer hora?\n",
    "df.filter(df.horario.like(\"%38%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d452a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos filtrar os dados retornados com a função where()\n",
    "df.where(\"entrega == 'Entrega 2'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01008ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos filtrar os dados retornados com a função where()\n",
    "df.where(\"id_veiculo > 400\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b13b9fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Where baseado em lista\n",
    "lista_id_veiculos = [298, 300, 400]\n",
    "df.where(df.id_veiculo.isin(lista_id_veiculos)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89ced5",
   "metadata": {},
   "source": [
    "### Métodos Order By e Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e7a0f",
   "metadata": {},
   "source": [
    "Você pode usar a função sort() ou orderBy() do Spark para classificar um DataFrame por \n",
    "ordem crescente ou decrescente com base em uma ou várias colunas. As duas funções geram o \n",
    "mesmo resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19f1c43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "+----------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordenando a seleção das linhas\n",
    "df.sort(\"horario\", \"entrega\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb649aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "+----------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mesmo resultado anterior mas com a função col()\n",
    "df.sort(col(\"horario\"), col(\"entrega\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "497f34f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "+----------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ou usamos Order By\n",
    "df.orderBy(col(\"horario\"), col(\"entrega\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5bfa0d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "+----------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordena o resultado em ordem decrescente \n",
    "df.sort(df.horario.desc(), df.entrega.desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "431e51cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "+----------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lembre-se que podemos usar SQL\n",
    "spark.sql(\"select id_veiculo, entrega, horario from tb_logistica ORDER BY horario desc\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d7b02",
   "metadata": {},
   "source": [
    "### Métodos Map, flatMap e Explode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447b119",
   "metadata": {},
   "source": [
    "O método Spark map() é uma transformação RDD que é usada para aplicar a função de \n",
    "transformação (lambda) em cada elemento de um RDD e retorna um novo RDD. \n",
    "A transformação map() é usada para aplicar quaisquer operações complexas como \n",
    "adicionar uma coluna, atualizar uma coluna, transformar os dados, etc. A saída das \n",
    "transformações map() sempre deve ter o mesmo número de registros que a entrada.\n",
    "\n",
    "O método Spark flatMap() é uma operação de transformação que nivela o RDD depois de \n",
    "aplicar a função em cada elemento e retorna um novo RDD. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eec899",
   "metadata": {},
   "source": [
    "Função map( ) em Python: https://docs.python.org/3.9/library/functions.html#map\n",
    "\n",
    "Função map( ) do Pandas: https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html\n",
    "\n",
    "Função map( ) do Spark: https://spark.apache.org/docs/latest/api/sql/index.html#map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e13b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|      novo_id|entrega|\n",
      "+-------------+-------+\n",
      "|298,Entrega 1|  7:58a|\n",
      "|298,Entrega 2|  8:04a|\n",
      "|298,Entrega 3|  8:17a|\n",
      "|298,Entrega 4|  8:28a|\n",
      "|298,Entrega 5|  8:33a|\n",
      "|298,Entrega 6|  8:39a|\n",
      "|298,Entrega 7|  9:07a|\n",
      "|315,Entrega 1|  6:05a|\n",
      "|315,Entrega 2|  6:14a|\n",
      "|315,Entrega 3|  6:24a|\n",
      "|315,Entrega 4|  6:38a|\n",
      "|315,Entrega 5|  6:45a|\n",
      "|315,Entrega 6|  6:56a|\n",
      "|315,Entrega 7|  7:32a|\n",
      "|457,Entrega 1|  5:04a|\n",
      "|457,Entrega 2|  5:13a|\n",
      "|457,Entrega 3|  5:27a|\n",
      "|457,Entrega 4|  5:39a|\n",
      "|457,Entrega 5|  5:47a|\n",
      "|457,Entrega 6|  6:21a|\n",
      "+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Maps são aplicados em RDDs e por isso precisamos converter o dataframe para RDD\n",
    "# O método Map retorna um RDD e por isso temos que converter de volta para dataframe\n",
    "rdd2 = df.rdd.map(lambda x: (x[0] + \",\" + x[1], x[2]))\n",
    "df2 = rdd2.toDF(['novo_id', 'entrega'])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc989615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_veiculo', 'entrega', 'horario']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88ef1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos uma função que manipula as colunas\n",
    "def manipula_colunas(x):\n",
    "    coluna1 = x.id_veiculo\n",
    "    coluna2 = x.entrega\n",
    "    novo_id = coluna1 + \"-\" + coluna2\n",
    "    coluna3 = x.horario\n",
    "    return (novo_id, coluna3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "756380d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos a função map para aplicar a função lambda (anônima), que aplica a função manipula_colunas a cada linha do RDD\n",
    "rdd2 = df.rdd.map(lambda x: manipula_colunas(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74370ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('298-Entrega 1', '7:58a'),\n",
       " ('298-Entrega 2', '8:04a'),\n",
       " ('298-Entrega 3', '8:17a'),\n",
       " ('298-Entrega 4', '8:28a'),\n",
       " ('298-Entrega 5', '8:33a'),\n",
       " ('298-Entrega 6', '8:39a'),\n",
       " ('298-Entrega 7', '9:07a'),\n",
       " ('315-Entrega 1', '6:05a'),\n",
       " ('315-Entrega 2', '6:14a'),\n",
       " ('315-Entrega 3', '6:24a'),\n",
       " ('315-Entrega 4', '6:38a'),\n",
       " ('315-Entrega 5', '6:45a'),\n",
       " ('315-Entrega 6', '6:56a'),\n",
       " ('315-Entrega 7', '7:32a'),\n",
       " ('457-Entrega 1', '5:04a'),\n",
       " ('457-Entrega 2', '5:13a'),\n",
       " ('457-Entrega 3', '5:27a'),\n",
       " ('457-Entrega 4', '5:39a'),\n",
       " ('457-Entrega 5', '5:47a'),\n",
       " ('457-Entrega 6', '6:21a'),\n",
       " ('457-Entrega 7', '6:38a')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect no RDD\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "514c1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O método flatMap requer uma lista no formato RDD\n",
    "# Vamos criar uma lista\n",
    "data = [\"A Data Science Academy\",\n",
    "        \"oferece cursos realmente incríveis\",\n",
    "        \"orientados às necessidades\",\n",
    "        \"do mercado de trabalho\",\n",
    "        \"e tudo mostrado passo a passo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "879aa116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertemos a lista em um RDD\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "becdf7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Data Science Academy\n",
      "oferece cursos realmente incríveis\n",
      "orientados às necessidades\n",
      "do mercado de trabalho\n",
      "e tudo mostrado passo a passo\n"
     ]
    }
   ],
   "source": [
    "# Imprime os elementos do RDD\n",
    "for element in rdd.collect():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c12afb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora aplicamos o FlatMap, que cria outro RDD\n",
    "rdd2 = rdd.flatMap(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "104b7e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "Data\n",
      "Science\n",
      "Academy\n",
      "oferece\n",
      "cursos\n",
      "realmente\n",
      "incríveis\n",
      "orientados\n",
      "às\n",
      "necessidades\n",
      "do\n",
      "mercado\n",
      "de\n",
      "trabalho\n",
      "e\n",
      "tudo\n",
      "mostrado\n",
      "passo\n",
      "a\n",
      "passo\n"
     ]
    }
   ],
   "source": [
    "# Imprime os elementos do RDD\n",
    "for element in rdd2.collect():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5decd794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode deve receber uma lista como argumento, mas essa lista pode estar em uma coluna de um dataframe\n",
    "from pyspark.sql.functions import explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b1defdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista\n",
    "array_estudantes = [('Bob', ['Python', 'R', 'Scala']),\n",
    "                    ('Maria', ['Java','Julia']),\n",
    "                    ('Zico', ['JavaScript', '']),\n",
    "                    ('Ana', [None, None])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7fc8ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array_estudantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "473fb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a lista para dataframe\n",
    "df_estudantes = spark.createDataFrame(data = array_estudantes, schema = ['aluno', 'linguagem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90bbfa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_estudantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4bd024e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aluno: string (nullable = true)\n",
      " |-- col: string (nullable = true)\n",
      "\n",
      "+-----+----------+\n",
      "|aluno|       col|\n",
      "+-----+----------+\n",
      "|  Bob|    Python|\n",
      "|  Bob|         R|\n",
      "|  Bob|     Scala|\n",
      "|Maria|      Java|\n",
      "|Maria|     Julia|\n",
      "| Zico|JavaScript|\n",
      "| Zico|          |\n",
      "|  Ana|      NULL|\n",
      "|  Ana|      NULL|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select com explode\n",
    "df2 = df_estudantes.select(df_estudantes.aluno, explode(df_estudantes.linguagem))\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a4c83d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_veiculo', 'entrega', 'horario']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2c037237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foreach\n",
    "df.foreach(lambda x: print(x[\"id_veiculo\"] + \",\" + x[\"entrega\"] + \",\" + x[\"horario\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ea6b1",
   "metadata": {},
   "source": [
    "## Agregação com Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21297c6d",
   "metadata": {},
   "source": [
    "> Agregação com Funções do Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b9fb1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_veiculo', 'entrega', 'horario']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d0e9a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|id_veiculo|count|\n",
      "+----------+-----+\n",
      "|       298|    7|\n",
      "|       457|    7|\n",
      "|       315|    7|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d6ffa175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|id_veiculo|min(horario)|\n",
      "+----------+------------+\n",
      "|       298|       7:58a|\n",
      "|       315|       6:05a|\n",
      "|       457|       5:04a|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').agg({'horario':'min'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eceb8fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|id_veiculo|max(horario)|\n",
      "+----------+------------+\n",
      "|       298|       9:07a|\n",
      "|       315|       7:32a|\n",
      "|       457|       6:38a|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').agg({'horario':'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50f8d1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|id_veiculo|count(horario)|\n",
      "+----------+--------------+\n",
      "|       298|             7|\n",
      "|       457|             7|\n",
      "|       315|             7|\n",
      "+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').agg({'horario':'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c73f22e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|id_veiculo|numero_entregas|\n",
      "+----------+---------------+\n",
      "|       298|              7|\n",
      "|       457|              7|\n",
      "|       315|              7|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').agg({'horario':'count'}).withColumnRenamed('count(horario)', 'numero_entregas').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1a408a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+\n",
      "|id_veiculo|hora_primeira_entrega|\n",
      "+----------+---------------------+\n",
      "|       298|                7:58a|\n",
      "|       315|                6:05a|\n",
      "|       457|                5:04a|\n",
      "+----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').agg({'horario':'min'}).withColumnRenamed('min(horario)', 'hora_primeira_entrega').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62dd1da",
   "metadata": {},
   "source": [
    "> Agregação com Queries SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab40494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|id_veiculo|numero_entregas|\n",
      "+----------+---------------+\n",
      "|       298|              7|\n",
      "|       457|              7|\n",
      "|       315|              7|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usando função SQL do SparkSQL\n",
    "df.groupBy(\"id_veiculo\").count().withColumnRenamed('count', 'numero_entregas').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e355668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Número de entregas por id_veiculo\n",
    "query = \"\"\"\n",
    "SELECT id_veiculo, COUNT(*) AS numero_entregas\n",
    "FROM tb_logistica\n",
    "GROUP BY id_veiculo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa96a11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|id_veiculo|numero_entregas|\n",
      "+----------+---------------+\n",
      "|       298|              7|\n",
      "|       457|              7|\n",
      "|       315|              7|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4f30be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Número de entregas por horário\n",
    "query = \"\"\"\n",
    "SELECT horario, COUNT(*) AS numero_entregas\n",
    "FROM tb_logistica\n",
    "GROUP BY horario\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a164d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|horario|numero_entregas|\n",
      "+-------+---------------+\n",
      "|  8:33a|              1|\n",
      "|  6:45a|              1|\n",
      "|  8:28a|              1|\n",
      "|  5:39a|              1|\n",
      "|  8:17a|              1|\n",
      "|  8:39a|              1|\n",
      "|  7:32a|              1|\n",
      "|  6:56a|              1|\n",
      "|  5:04a|              1|\n",
      "|  6:14a|              1|\n",
      "|  5:13a|              1|\n",
      "|  8:04a|              1|\n",
      "|  6:05a|              1|\n",
      "|  5:27a|              1|\n",
      "|  6:24a|              1|\n",
      "|  7:58a|              1|\n",
      "|  5:47a|              1|\n",
      "|  6:38a|              2|\n",
      "|  9:07a|              1|\n",
      "|  6:21a|              1|\n",
      "+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6b11ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Horário que teve mais de uma entrega\n",
    "query = \"\"\"\n",
    "SELECT horario, COUNT(*) AS hora_ultima_entrega\n",
    "FROM tb_logistica\n",
    "GROUP BY horario\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b8ab3682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|horario|hora_ultima_entrega|\n",
      "+-------+-------------------+\n",
      "|  6:38a|                  2|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3092d8",
   "metadata": {},
   "source": [
    "> Podemos ainda fazer Pivot de um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66207c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de horários de entregas\n",
    "lista_horarios = ['5:13a', '6:38a', '7:32a', '8:04a', '9:07a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "402d8afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testamos o filtro\n",
    "df.filter(df.horario.isin(lista_horarios)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "455ffe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot é uma função de agregação no Spark\n",
    "df_pivot = df.filter(df.horario.isin(lista_horarios)).groupBy(\"id_veiculo\").pivot(\"horario\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "12212ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+\n",
      "|id_veiculo|5:13a|6:38a|7:32a|8:04a|9:07a|\n",
      "+----------+-----+-----+-----+-----+-----+\n",
      "|       298| NULL| NULL| NULL|    1|    1|\n",
      "|       457|    1|    1| NULL| NULL| NULL|\n",
      "|       315| NULL|    1|    1| NULL| NULL|\n",
      "+----------+-----+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pivot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84a7b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos converter o Spark Dataframe para Pandas Dataframe a fim de facilitar a visualização\n",
    "pandasDF = df_pivot.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "571cb462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_veiculo</th>\n",
       "      <th>5:13a</th>\n",
       "      <th>6:38a</th>\n",
       "      <th>7:32a</th>\n",
       "      <th>8:04a</th>\n",
       "      <th>9:07a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_veiculo  5:13a  6:38a  7:32a  8:04a  9:07a\n",
       "0        298    NaN    NaN    NaN    1.0    1.0\n",
       "1        457    1.0    1.0    NaN    NaN    NaN\n",
       "2        315    NaN    1.0    1.0    NaN    NaN"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandasDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6010fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Número de entregas por id_veiculo\n",
    "query = \"\"\"\n",
    "SELECT * FROM (\n",
    "  SELECT id_veiculo, horario\n",
    "  FROM tb_logistica\n",
    ")\n",
    "PIVOT (\n",
    "  COUNT(*)\n",
    "  FOR horario in (\n",
    "    '5:13a', '6:38a', '7:32a', '8:04a', '9:07a'\n",
    "  )\n",
    ")\n",
    "ORDER BY id_veiculo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26d9f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+\n",
      "|id_veiculo|5:13a|6:38a|7:32a|8:04a|9:07a|\n",
      "+----------+-----+-----+-----+-----+-----+\n",
      "|       298| NULL| NULL| NULL|    1|    1|\n",
      "|       315| NULL|    1|    1| NULL| NULL|\n",
      "|       457|    1|    1| NULL| NULL| NULL|\n",
      "+----------+-----+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9292428",
   "metadata": {},
   "source": [
    "## SQL Window Function Para Agregação ao Longo do Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18afaee",
   "metadata": {},
   "source": [
    "As funções Window são usadas para calcular resultados em um intervalo de linhas. Ou \n",
    "seja, ao contrário do Group By que permite a agregação no nível de coluna, funções Window \n",
    "permitem agregação no nível de linha. Entretanto, elas não são exclusivas e podemos ter funções \n",
    "Window e Group By na mesma query SQL.\n",
    "\n",
    "As principais funções Window são: row_number(), rank(), percent_rank(), dense_rank(), \n",
    "ntile(), lag() e lead() e o particionamento de linhas é feito com a função OVER(). Normalmente \n",
    "precisamos ordenar os dados pela coluna que representa datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "94bdb4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isso aqui é agregação por coluna (e por isso usamos o group by)\n",
    "query = \"\"\"\n",
    "SELECT id_veiculo, COUNT(horario) AS numero_entregas\n",
    "FROM tb_logistica\n",
    "GROUP BY id_veiculo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e45f87cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|id_veiculo|numero_entregas|\n",
      "+----------+---------------+\n",
      "|       298|              7|\n",
      "|       457|              7|\n",
      "|       315|              7|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca0183fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isso aqui é agregação por linha (e por isso usamos função window)\n",
    "# Isso é útil quando os dados estão embaralhados e queremos organizar com base em um critério\n",
    "# Por exemplo: \n",
    "# Para cada entrega (entrega 1, entrega 2, etc..), quais veículos fizeram a entrega primeiro em cada hora?\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT id_veiculo, entrega, horario,\n",
    "ROW_NUMBER() OVER (PARTITION BY entrega ORDER BY horario) AS ranking\n",
    "FROM tb_logistica\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b3c9178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+-------+\n",
      "|id_veiculo|  entrega|horario|ranking|\n",
      "+----------+---------+-------+-------+\n",
      "|       457|Entrega 1|  5:04a|      1|\n",
      "|       315|Entrega 1|  6:05a|      2|\n",
      "|       298|Entrega 1|  7:58a|      3|\n",
      "|       457|Entrega 2|  5:13a|      1|\n",
      "|       315|Entrega 2|  6:14a|      2|\n",
      "|       298|Entrega 2|  8:04a|      3|\n",
      "|       457|Entrega 3|  5:27a|      1|\n",
      "|       315|Entrega 3|  6:24a|      2|\n",
      "|       298|Entrega 3|  8:17a|      3|\n",
      "|       457|Entrega 4|  5:39a|      1|\n",
      "|       315|Entrega 4|  6:38a|      2|\n",
      "|       298|Entrega 4|  8:28a|      3|\n",
      "|       457|Entrega 5|  5:47a|      1|\n",
      "|       315|Entrega 5|  6:45a|      2|\n",
      "|       298|Entrega 5|  8:33a|      3|\n",
      "|       457|Entrega 6|  6:21a|      1|\n",
      "|       315|Entrega 6|  6:56a|      2|\n",
      "|       298|Entrega 6|  8:39a|      3|\n",
      "|       457|Entrega 7|  6:38a|      1|\n",
      "|       315|Entrega 7|  7:32a|      2|\n",
      "|       298|Entrega 7|  9:07a|      3|\n",
      "+----------+---------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd03adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT id_veiculo, entrega, horario,\n",
    "ROW_NUMBER() OVER (PARTITION BY id_veiculo ORDER BY horario) AS ranking\n",
    "FROM tb_logistica\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0b94230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+-------+\n",
      "|id_veiculo|  entrega|horario|ranking|\n",
      "+----------+---------+-------+-------+\n",
      "|       298|Entrega 1|  7:58a|      1|\n",
      "|       298|Entrega 2|  8:04a|      2|\n",
      "|       298|Entrega 3|  8:17a|      3|\n",
      "|       298|Entrega 4|  8:28a|      4|\n",
      "|       298|Entrega 5|  8:33a|      5|\n",
      "|       298|Entrega 6|  8:39a|      6|\n",
      "|       298|Entrega 7|  9:07a|      7|\n",
      "|       315|Entrega 1|  6:05a|      1|\n",
      "|       315|Entrega 2|  6:14a|      2|\n",
      "|       315|Entrega 3|  6:24a|      3|\n",
      "|       315|Entrega 4|  6:38a|      4|\n",
      "|       315|Entrega 5|  6:45a|      5|\n",
      "|       315|Entrega 6|  6:56a|      6|\n",
      "|       315|Entrega 7|  7:32a|      7|\n",
      "|       457|Entrega 1|  5:04a|      1|\n",
      "|       457|Entrega 2|  5:13a|      2|\n",
      "|       457|Entrega 3|  5:27a|      3|\n",
      "|       457|Entrega 4|  5:39a|      4|\n",
      "|       457|Entrega 5|  5:47a|      5|\n",
      "|       457|Entrega 6|  6:21a|      6|\n",
      "|       457|Entrega 7|  6:38a|      7|\n",
      "+----------+---------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "29a9428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---+\n",
      "|id_veiculo|  entrega|horario| id|\n",
      "+----------+---------+-------+---+\n",
      "|       457|Entrega 1|  5:04a|  1|\n",
      "|       315|Entrega 1|  6:05a|  2|\n",
      "|       298|Entrega 1|  7:58a|  3|\n",
      "|       457|Entrega 2|  5:13a|  1|\n",
      "|       315|Entrega 2|  6:14a|  2|\n",
      "|       298|Entrega 2|  8:04a|  3|\n",
      "|       457|Entrega 3|  5:27a|  1|\n",
      "|       315|Entrega 3|  6:24a|  2|\n",
      "|       298|Entrega 3|  8:17a|  3|\n",
      "|       457|Entrega 4|  5:39a|  1|\n",
      "|       315|Entrega 4|  6:38a|  2|\n",
      "|       298|Entrega 4|  8:28a|  3|\n",
      "|       457|Entrega 5|  5:47a|  1|\n",
      "|       315|Entrega 5|  6:45a|  2|\n",
      "|       298|Entrega 5|  8:33a|  3|\n",
      "|       457|Entrega 6|  6:21a|  1|\n",
      "|       315|Entrega 6|  6:56a|  2|\n",
      "|       298|Entrega 6|  8:39a|  3|\n",
      "|       457|Entrega 7|  6:38a|  1|\n",
      "|       315|Entrega 7|  7:32a|  2|\n",
      "|       298|Entrega 7|  9:07a|  3|\n",
      "+----------+---------+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mesmo resultado anterior mas utilizando Função SparkSQL\n",
    "df.withColumn(\"id\", row_number().over(Window.partitionBy('entrega').orderBy('horario'))).show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "635c7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Para cada entrega mostra o horario de entrega anterior por id_veiculo\n",
    "query = \"\"\"\n",
    "SELECT id_veiculo, entrega, horario,\n",
    "LAG(horario, 1) OVER (PARTITION BY id_veiculo ORDER BY horario) AS entrega_anterior\n",
    "FROM tb_logistica\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "64340401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+----------------+\n",
      "|id_veiculo|  entrega|horario|entrega_anterior|\n",
      "+----------+---------+-------+----------------+\n",
      "|       298|Entrega 1|  7:58a|            NULL|\n",
      "|       298|Entrega 2|  8:04a|           7:58a|\n",
      "|       298|Entrega 3|  8:17a|           8:04a|\n",
      "|       298|Entrega 4|  8:28a|           8:17a|\n",
      "|       298|Entrega 5|  8:33a|           8:28a|\n",
      "|       298|Entrega 6|  8:39a|           8:33a|\n",
      "|       298|Entrega 7|  9:07a|           8:39a|\n",
      "|       315|Entrega 1|  6:05a|            NULL|\n",
      "|       315|Entrega 2|  6:14a|           6:05a|\n",
      "|       315|Entrega 3|  6:24a|           6:14a|\n",
      "|       315|Entrega 4|  6:38a|           6:24a|\n",
      "|       315|Entrega 5|  6:45a|           6:38a|\n",
      "|       315|Entrega 6|  6:56a|           6:45a|\n",
      "|       315|Entrega 7|  7:32a|           6:56a|\n",
      "|       457|Entrega 1|  5:04a|            NULL|\n",
      "|       457|Entrega 2|  5:13a|           5:04a|\n",
      "|       457|Entrega 3|  5:27a|           5:13a|\n",
      "|       457|Entrega 4|  5:39a|           5:27a|\n",
      "|       457|Entrega 5|  5:47a|           5:39a|\n",
      "|       457|Entrega 6|  6:21a|           5:47a|\n",
      "|       457|Entrega 7|  6:38a|           6:21a|\n",
      "+----------+---------+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "726b83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "id_veiculo, entrega, horario,\n",
    "LEAD(horario, 1) OVER (PARTITION BY id_veiculo ORDER BY horario) AS proxima_entrega\n",
    "FROM tb_logistica\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "821d6aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+\n",
      "|id_veiculo|  entrega|horario|proxima_entrega|\n",
      "+----------+---------+-------+---------------+\n",
      "|       298|Entrega 1|  7:58a|          8:04a|\n",
      "|       298|Entrega 2|  8:04a|          8:17a|\n",
      "|       298|Entrega 3|  8:17a|          8:28a|\n",
      "|       298|Entrega 4|  8:28a|          8:33a|\n",
      "|       298|Entrega 5|  8:33a|          8:39a|\n",
      "|       298|Entrega 6|  8:39a|          9:07a|\n",
      "|       298|Entrega 7|  9:07a|           NULL|\n",
      "|       315|Entrega 1|  6:05a|          6:14a|\n",
      "|       315|Entrega 2|  6:14a|          6:24a|\n",
      "|       315|Entrega 3|  6:24a|          6:38a|\n",
      "|       315|Entrega 4|  6:38a|          6:45a|\n",
      "|       315|Entrega 5|  6:45a|          6:56a|\n",
      "|       315|Entrega 6|  6:56a|          7:32a|\n",
      "|       315|Entrega 7|  7:32a|           NULL|\n",
      "|       457|Entrega 1|  5:04a|          5:13a|\n",
      "|       457|Entrega 2|  5:13a|          5:27a|\n",
      "|       457|Entrega 3|  5:27a|          5:39a|\n",
      "|       457|Entrega 4|  5:39a|          5:47a|\n",
      "|       457|Entrega 5|  5:47a|          6:21a|\n",
      "|       457|Entrega 6|  6:21a|          6:38a|\n",
      "|       457|Entrega 7|  6:38a|           NULL|\n",
      "+----------+---------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query e mostra o resultado\n",
    "spark.sql(query).show(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5863d6a7",
   "metadata": {},
   "source": [
    "## Usando Partições com Spark SQL\n",
    "* A função **over()** no Spark SQL corresponde a cláusula **OVER** em SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3ba80c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre a janela nos dados\n",
    "janela = Window.partitionBy('id_veiculo').orderBy('horario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d3a87ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.window.WindowSpec"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(janela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee440cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o Lead (desloca os dados no tempo) sobre (over) a janela (window)\n",
    "dfx = df.withColumn('proxima_entrega', lead('horario', 1).over(janela))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aad2b7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+\n",
      "|id_veiculo|  entrega|horario|proxima_entrega|\n",
      "+----------+---------+-------+---------------+\n",
      "|       298|Entrega 1|  7:58a|          8:04a|\n",
      "|       298|Entrega 2|  8:04a|          8:17a|\n",
      "|       298|Entrega 3|  8:17a|          8:28a|\n",
      "|       298|Entrega 4|  8:28a|          8:33a|\n",
      "|       298|Entrega 5|  8:33a|          8:39a|\n",
      "|       298|Entrega 6|  8:39a|          9:07a|\n",
      "|       298|Entrega 7|  9:07a|           NULL|\n",
      "|       315|Entrega 1|  6:05a|          6:14a|\n",
      "|       315|Entrega 2|  6:14a|          6:24a|\n",
      "|       315|Entrega 3|  6:24a|          6:38a|\n",
      "|       315|Entrega 4|  6:38a|          6:45a|\n",
      "|       315|Entrega 5|  6:45a|          6:56a|\n",
      "|       315|Entrega 6|  6:56a|          7:32a|\n",
      "|       315|Entrega 7|  7:32a|           NULL|\n",
      "|       457|Entrega 1|  5:04a|          5:13a|\n",
      "|       457|Entrega 2|  5:13a|          5:27a|\n",
      "|       457|Entrega 3|  5:27a|          5:39a|\n",
      "|       457|Entrega 4|  5:39a|          5:47a|\n",
      "|       457|Entrega 5|  5:47a|          6:21a|\n",
      "|       457|Entrega 6|  6:21a|          6:38a|\n",
      "|       457|Entrega 7|  6:38a|           NULL|\n",
      "+----------+---------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfx.show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "50b3dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+\n",
      "|id_veiculo|  entrega|horario|proxima_entrega|\n",
      "+----------+---------+-------+---------------+\n",
      "|       298|Entrega 1|  7:58a|          8:04a|\n",
      "|       298|Entrega 2|  8:04a|          8:17a|\n",
      "|       298|Entrega 3|  8:17a|          8:28a|\n",
      "|       298|Entrega 4|  8:28a|          8:33a|\n",
      "|       298|Entrega 5|  8:33a|          8:39a|\n",
      "|       298|Entrega 6|  8:39a|          9:07a|\n",
      "|       298|Entrega 7|  9:07a|           NULL|\n",
      "|       315|Entrega 1|  6:05a|          6:14a|\n",
      "|       315|Entrega 2|  6:14a|          6:24a|\n",
      "|       315|Entrega 3|  6:24a|          6:38a|\n",
      "|       315|Entrega 4|  6:38a|          6:45a|\n",
      "|       315|Entrega 5|  6:45a|          6:56a|\n",
      "|       315|Entrega 6|  6:56a|          7:32a|\n",
      "|       315|Entrega 7|  7:32a|           NULL|\n",
      "|       457|Entrega 1|  5:04a|          5:13a|\n",
      "|       457|Entrega 2|  5:13a|          5:27a|\n",
      "|       457|Entrega 3|  5:27a|          5:39a|\n",
      "|       457|Entrega 4|  5:39a|          5:47a|\n",
      "|       457|Entrega 5|  5:47a|          6:21a|\n",
      "|       457|Entrega 6|  6:21a|          6:38a|\n",
      "|       457|Entrega 7|  6:38a|           NULL|\n",
      "+----------+---------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mesmo exemplo anterior mas em uma linha de código\n",
    "df_dot = df.withColumn('proxima_entrega', lead('horario', 1)\n",
    ".over(Window.partitionBy('id_veiculo')\n",
    ".orderBy('horario'))).show(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be183d",
   "metadata": {},
   "source": [
    "## Parse de Data Para Agregação ao Longo do Tempo\n",
    "\n",
    "Calcule o tempo (em minutos) para a próxima entrega de cada veículo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "74ab9135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define o time parser policy\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f2a3f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a janela\n",
    "window = Window.partitionBy('id_veiculo').orderBy('horario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5eda858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------------+\n",
      "|id_veiculo|  entrega|horario|tempo_proxima_entrega|\n",
      "+----------+---------+-------+---------------------+\n",
      "|       298|Entrega 1|  7:58a|                  6.0|\n",
      "|       298|Entrega 2|  8:04a|                 13.0|\n",
      "|       298|Entrega 3|  8:17a|                 11.0|\n",
      "|       298|Entrega 4|  8:28a|                  5.0|\n",
      "|       298|Entrega 5|  8:33a|                  6.0|\n",
      "|       298|Entrega 6|  8:39a|                 28.0|\n",
      "|       298|Entrega 7|  9:07a|                 NULL|\n",
      "|       315|Entrega 1|  6:05a|                  9.0|\n",
      "|       315|Entrega 2|  6:14a|                 10.0|\n",
      "|       315|Entrega 3|  6:24a|                 14.0|\n",
      "|       315|Entrega 4|  6:38a|                  7.0|\n",
      "|       315|Entrega 5|  6:45a|                 11.0|\n",
      "|       315|Entrega 6|  6:56a|                 36.0|\n",
      "|       315|Entrega 7|  7:32a|                 NULL|\n",
      "|       457|Entrega 1|  5:04a|                  9.0|\n",
      "|       457|Entrega 2|  5:13a|                 14.0|\n",
      "|       457|Entrega 3|  5:27a|                 12.0|\n",
      "|       457|Entrega 4|  5:39a|                  8.0|\n",
      "|       457|Entrega 5|  5:47a|                 34.0|\n",
      "|       457|Entrega 6|  6:21a|                 17.0|\n",
      "|       457|Entrega 7|  6:38a|                 NULL|\n",
      "+----------+---------+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregação por linha para calcular a diferença entre os horários\n",
    "dot_df = df.withColumn('tempo_proxima_entrega', \n",
    "                       (unix_timestamp(lead('horario', 1).over(window),'H:m') \n",
    "                        - unix_timestamp('horario', 'H:m'))/60).show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3c9fc738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Calculamos aqui a diferença de tempo de uma entrega para outra por id_veiculo (partição)\n",
    "query = \"\"\"\n",
    "SELECT *, \n",
    "(UNIX_TIMESTAMP(LEAD(horario, 1) OVER (PARTITION BY id_veiculo ORDER BY horario),'H:m') \n",
    "- UNIX_TIMESTAMP(horario, 'H:m'))/60 AS tempo_proxima_entrega\n",
    "FROM tb_logistica \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b17bd3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bd821aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------------+\n",
      "|id_veiculo|  entrega|horario|tempo_proxima_entrega|\n",
      "+----------+---------+-------+---------------------+\n",
      "|       298|Entrega 1|  7:58a|                  6.0|\n",
      "|       298|Entrega 2|  8:04a|                 13.0|\n",
      "|       298|Entrega 3|  8:17a|                 11.0|\n",
      "|       298|Entrega 4|  8:28a|                  5.0|\n",
      "|       298|Entrega 5|  8:33a|                  6.0|\n",
      "|       298|Entrega 6|  8:39a|                 28.0|\n",
      "|       298|Entrega 7|  9:07a|                 NULL|\n",
      "|       315|Entrega 1|  6:05a|                  9.0|\n",
      "|       315|Entrega 2|  6:14a|                 10.0|\n",
      "|       315|Entrega 3|  6:24a|                 14.0|\n",
      "|       315|Entrega 4|  6:38a|                  7.0|\n",
      "|       315|Entrega 5|  6:45a|                 11.0|\n",
      "|       315|Entrega 6|  6:56a|                 36.0|\n",
      "|       315|Entrega 7|  7:32a|                 NULL|\n",
      "|       457|Entrega 1|  5:04a|                  9.0|\n",
      "|       457|Entrega 2|  5:13a|                 14.0|\n",
      "|       457|Entrega 3|  5:27a|                 12.0|\n",
      "|       457|Entrega 4|  5:39a|                  8.0|\n",
      "|       457|Entrega 5|  5:47a|                 34.0|\n",
      "|       457|Entrega 6|  6:21a|                 17.0|\n",
      "|       457|Entrega 7|  6:38a|                 NULL|\n",
      "+----------+---------+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_df.show(21)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
